{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORNELL MOVIE CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines_path = \"/Users/rohan/Desktop/projects/python-chatbot/movie_lines.txt\"\n",
    "movie_conversations_path = \"/Users/rohan/Desktop/projects/python-chatbot/movie_conversations.txt\"\n",
    "movie_conversation_fields = ['char1ID', 'char2ID', 'movieID', 'utterances']\n",
    "movie_lines_fields = ['lineId', 'charId', 'movieId', 'charname', 'text']\n",
    "\n",
    "def splitConversations(max_len=20, fast_preprocessing=True):\n",
    "    conversations = getconv()\n",
    "    data = []\n",
    "    for i, conversation in enumerate(tqdm(conversations)):\n",
    "        lines = conversation['lines']\n",
    "        for i in range(len(lines) - 1):\n",
    "            request = preprocess_text(lines[i])\n",
    "            reply = preprocess_text(lines[i + 1])\n",
    "            if 0 < len(request.split()) <= max_len and 0 < len(reply.split()) <= max_len:\n",
    "                data += [{'request': request,'reply':reply}]\n",
    "    return data\n",
    "\n",
    "def getlines():\n",
    "    with open(movie_lines_path, 'r', encoding='iso-8859-1') as f:\n",
    "        lines = {}\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            lineobj = {}\n",
    "            for i, field in enumerate(movie_lines_fields):\n",
    "                lineobj[field] = values[i]\n",
    "                #lineobj['id'] = int(re.sub('L','',lineobj['lineId']))\n",
    "            lines[lineobj['lineId']] = lineobj\n",
    "    return(lines)\n",
    "\n",
    "def getconv():\n",
    "    lines = getlines()\n",
    "    with open(movie_conversations_path, 'r', encoding='iso-8859-1') as f:\n",
    "        conversations = []\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            #print(len(values))\n",
    "            lineobj = {}\n",
    "            for i, field in enumerate(movie_conversation_fields):\n",
    "                lineobj[field] = values[i]\n",
    "            lineIds = ast.literal_eval(lineobj[\"utterances\"])\n",
    "            lineobj['lines'] = []\n",
    "            for lineid in lineIds:\n",
    "                lineobj['lines'].append(lines[lineid]['text'])\n",
    "            conversations.append(lineobj)\n",
    "    return conversations\n",
    "\n",
    "def preprocess_text(line):\n",
    "    GOOD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#+_]')\n",
    "    REPLACE_SEVERAL_SPACES = re.compile('\\s+')\n",
    "    line = line.lower()\n",
    "    line = re.sub('\\n','', line)\n",
    "    line = re.sub('can\\'t','cannot', line)\n",
    "    line = re.sub('won\\'t','will not', line)\n",
    "    line = re.sub('\\'ll',' will', line)\n",
    "    line = re.sub('n\\' t',' not',line)\n",
    "    line = re.sub('\\'m',' am', line)\n",
    "    line = re.sub('\\'d',' would', line)\n",
    "    line = re.sub('\\'re',' are', line)\n",
    "    line = re.sub('\\'ve',' have', line)\n",
    "    line = re.sub('\\'s',' is', line)\n",
    "    line = REPLACE_BY_SPACE_RE.sub(' ', line)\n",
    "    line = GOOD_SYMBOLS_RE.sub('', line)\n",
    "    line = REPLACE_SEVERAL_SPACES.sub(' ', line)\n",
    "    return line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:07<00:00, 10548.63it/s]\n"
     ]
    }
   ],
   "source": [
    "cornell_data = splitConversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'request': 'not the hacking and gagging and spitting part please',\n",
       "  'reply': 'okay then how bout we try out some french cuisine saturday night'},\n",
       " {'request': 'you are asking me out that is so cute what is your name again',\n",
       "  'reply': 'forget it'},\n",
       " {'request': 'no no it is my fault we didnt have a proper introduction',\n",
       "  'reply': 'cameron'},\n",
       " {'request': 'gosh if only we could find kat a boyfriend',\n",
       "  'reply': 'let me see what i can do'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167497"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cornell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cornell_data, open('cornell_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------\n",
    "## -----------------------------------------------------------------------------------------------------\n",
    "## -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "from time import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_subtitles_path = \"/Users/rohan/Desktop/projects/python-chatbot/OpenSubtitles/xml/en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(open_subtitles_path)\n",
    "xml_files = []\n",
    "for i in files:\n",
    "    try:\n",
    "        filelist = os.listdir(open_subtitles_path+i)\n",
    "        for file in filelist:\n",
    "            try:\n",
    "                finallist = os.listdir(open_subtitles_path+i+\"/\"+file)\n",
    "                for x in finallist:\n",
    "                    if x.endswith('.xml'):\n",
    "                        xml_files.append(open_subtitles_path+i+\"/\"+file+\"/\"+x)\n",
    "            except NotADirectoryError:\n",
    "                if file.endswith('.xml'):\n",
    "                    xml_files.append(open_subtitles_path+i+\"/\"+file)\n",
    "    except NotADirectoryError:\n",
    "        if file.endswith('.xml'):\n",
    "                xml_files.append(open_subtitles_path+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genList(tree):\n",
    "    root = tree.getroot()\n",
    "    timeFormat = '%H:%M:%S'\n",
    "    maxDelta = datetime.timedelta(seconds=1)\n",
    "    startTime = datetime.datetime.min\n",
    "    strbuf = ''\n",
    "    sentList = []\n",
    "    for child in root:\n",
    "        for elem in child:\n",
    "            if elem.tag == 'time':\n",
    "                try:\n",
    "                    elemID = elem.attrib['id']\n",
    "                    elemVal = elem.attrib['value'][:-4]\n",
    "                    if elemID[-1] == 'S':\n",
    "                        startTime = datetime.datetime.strptime(elemVal, timeFormat)\n",
    "                    else:\n",
    "                        sentList.append((strbuf.strip(), startTime, datetime.datetime.strptime(elemVal, timeFormat)))\n",
    "                        strbuf = ''\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    strbuf = strbuf + \" \" + elem.text\n",
    "                except:\n",
    "                    pass\n",
    "    conversations = []\n",
    "    for idx in range(0, len(sentList) - 1):\n",
    "        cur = sentList[idx]\n",
    "        nxt = sentList[idx + 1]\n",
    "        if nxt[1] - cur[2] <= maxDelta and cur and nxt:\n",
    "            tmp = {}\n",
    "            tmp[\"lines\"] = []\n",
    "            tmp[\"lines\"].append(getLine(cur[0]))\n",
    "            tmp[\"lines\"].append(getLine(nxt[0]))\n",
    "            if filterqa(tmp):\n",
    "                conversations.append(tmp)\n",
    "    return conversations\n",
    "\n",
    "def getLine(sentence):\n",
    "    tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "    line = {}\n",
    "    line[\"text\"] = tag_re.sub('', sentence).replace('\\\\\\'','\\'').strip().lower()\n",
    "    return line\n",
    "\n",
    "\n",
    "def filterqa(lines):\n",
    "    # Use the followint to customize filtering of QA pairs\n",
    "    startwords = (\"what\", \"how\", \"when\", \"why\", \"where\", \"do\", \"did\", \"is\", \"are\", \"can\", \"could\", \"would\", \"will\")\n",
    "    question = lines[\"lines\"][0][\"text\"]\n",
    "    if not question.endswith('?'):\n",
    "        return False\n",
    "    if not question.split(' ')[0] in startwords:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConversation(files):\n",
    "    converations = []\n",
    "    for i,file in enumerate(tqdm(files)):\n",
    "        converations.extend(genList(ET.parse(file)))\n",
    "    return converations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2317/2317 [02:10<00:00, 17.73it/s]\n"
     ]
    }
   ],
   "source": [
    "opensub_conversations = getConversation(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68367/68367 [00:00<00:00, 965488.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, pair in enumerate(tqdm(opensub_conversations)):\n",
    "    questions.append(pair['lines'][0]['text'])\n",
    "    answers.append(pair['lines'][1]['text'])\n",
    "#    print(pair['lines'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell = pd.DataFrame(columns=['question','answer'])\n",
    "cornell['question'] = questions\n",
    "cornell['answer'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornell.to_csv(\"cornell_pairs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------\n",
    "## -----------------------------------------------------------------------------------------------------\n",
    "## -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlg_train(questions, answers, order=4):\n",
    "    lm = defaultdict(Counter)\n",
    "   # for cur_order in range(order):\n",
    "    pad = '~' * order\n",
    "    for i in range(len(questions)):\n",
    "        data = pad + questions[i] + answers[i]\n",
    "        for j in range(len(data) - order):\n",
    "            history, char = data[j:j+order], data[j+order]\n",
    "            lm[history][char] +=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def gen_letter(lm, history, order):\n",
    "    history = history[-order:]\n",
    "    dist = lm[history]\n",
    "    x = random()\n",
    "    for c, v in dist:\n",
    "        x = x - v\n",
    "        if x<=0: return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(question,lm, order, nletters=60):\n",
    "    pad = '~' * order\n",
    "    history = pad + question\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = gen_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no no trouble back theyll stay in touchthats more like thatw\n"
     ]
    }
   ],
   "source": [
    "lm = nlg_train(questions, answers, order=10)\n",
    "print( gen_text(lm,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rk herehuh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-b257fcb5db76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hi there'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-5acd9cf2bbc4>\u001b[0m in \u001b[0;36mgen_text\u001b[0;34m(question, lm, order, nletters)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnletters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-1a4236c3ef75>\u001b[0m in \u001b[0;36mgen_letter\u001b[0;34m(lm, history, order)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rk herehuh'"
     ]
    }
   ],
   "source": [
    "print(gen_text('hi there',lm,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
